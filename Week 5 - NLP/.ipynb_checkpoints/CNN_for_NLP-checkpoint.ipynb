{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxEcEPquOVU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99c617a1-8978-45e7-d4b4-172abc85d5e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "with open('/content/drive/MyDrive/GenAI_Wksp/Sentiment_Classification/data/reviews.txt', 'r') as f:\n",
        "  reviews = f.read()\n",
        "\n",
        "with open('/content/drive/MyDrive/GenAI_Wksp/Sentiment_Classification/data/labels.txt', 'r') as f:\n",
        "  labels = f.read()"
      ],
      "metadata": {
        "id": "BppGTZydP-x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviews[:1000])\n",
        "print()\n",
        "print(labels[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYvV2AmRRUJR",
        "outputId": "842c0bb9-bb49-4866-944a-b6b304f0452d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turn\n",
            "\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "negative\n",
            "positive\n",
            "neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "reviews = reviews.lower()\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "\n",
        "reviews_split = all_text.split('\\n')\n",
        "all_text = ' '.join(reviews_split)\n",
        "\n",
        "all_words = all_text.split()\n"
      ],
      "metadata": {
        "id": "4qmlh4tuR5Fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_split = labels.split('\\n')\n",
        "encoded_labels = np.array([1 if label == 'positive' else 0 for label in labels_split])\n"
      ],
      "metadata": {
        "id": "T9NZsNWUUvPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "review_lens = Counter([len(x.split()) for x in reviews_split])\n",
        "print(\"Zero lenght : {}\".format(review_lens[0]))\n",
        "print(\"Max lenght : {}\".format(max(review_lens)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om9ebmRgWbhf",
        "outputId": "172a5afe-5ff6-4030-e183-d706d3ea8018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero lenght : 1\n",
            "Max lenght : 2514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "non_zero_idx = [ii for ii, review in enumerate(reviews_split) if len(review.split()) != 0]\n",
        "\n",
        "reviews_split = [reviews_split[ii] for ii in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[ii] for ii in non_zero_idx])"
      ],
      "metadata": {
        "id": "1EwAgHadYgVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "embed_lookup = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/GenAI_Wksp/Sentiment_Classification/word2vec_model/GoogleNews-vectors-negative300-SLIM.bin',\n",
        "                                                 binary=True)"
      ],
      "metadata": {
        "id": "7qeCGI2YZyaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_words = []\n",
        "for  index, word in enumerate(embed_lookup.index_to_key):\n",
        "  pretrained_words.append(word)"
      ],
      "metadata": {
        "id": "UY-begIEea98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row_idx = 1\n",
        "\n",
        "word= pretrained_words[row_idx]\n",
        "embedding = embed_lookup[word]\n",
        "\n",
        "print(\"Size of Vocab: {}\\n\".format(len(pretrained_words)))\n",
        "print('Word in vocab: {}\\n'.format(word))\n",
        "print('Length of embedding: {}\\n'.format(len(embedding)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HssS4ZtffBFt",
        "outputId": "9655b653-d3af-43c7-d815-fca4e0d2a919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Vocab: 299567\n",
            "\n",
            "Word in vocab: for\n",
            "\n",
            "Length of embedding: 300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_all_reviews(embed_lookup, reviews_split):\n",
        "    reviews_words = [review.split() for review in reviews_split]\n",
        "\n",
        "    tokenized_reviews = []\n",
        "    for review in reviews_words:\n",
        "        ints = []\n",
        "        for word in review:\n",
        "            try:\n",
        "                idx = embed_lookup.key_to_index[word]\n",
        "            except:\n",
        "                idx = 0\n",
        "            ints.append(idx)\n",
        "        tokenized_reviews.append(ints)\n",
        "\n",
        "    return tokenized_reviews\n"
      ],
      "metadata": {
        "id": "tY6wHz9hgFuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_reviews = tokenize_all_reviews(embed_lookup, reviews_split)\n",
        "print(tokenized_reviews[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GAlekiGiQXL",
        "outputId": "61b62240-9d8a-48c1-d53a-05df978fb68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 137, 3, 0, 11620, 3799, 13, 1215, 10, 9, 194, 54, 12, 73, 61, 685, 41, 183, 243, 129, 12, 1663, 119, 72, 0, 9, 2989, 7334, 242, 159, 0, 453, 2, 0, 137, 1239, 19951, 3, 141, 1980, 0, 1898, 55, 3, 1663, 9, 11124, 0, 3857, 6663, 9, 20401, 295, 28, 45, 148, 157, 102, 27, 15452, 1663, 30714, 9, 65172, 0, 9, 844, 737, 47, 6585, 159, 0, 9, 668, 4365, 1003, 0, 27, 295, 56, 4365, 622, 9, 3832, 0, 43, 0, 897, 3187, 907, 0, 5396, 113, 9, 183, 4365, 1009, 3165, 10, 137, 0, 3288, 296, 10314, 4365, 6638, 213, 0, 8810, 40, 0, 116, 1663, 897, 2059, 0, 0, 137, 4365, 830, 2, 124, 2216, 0, 119, 782, 144, 2, 0, 137, 3, 330, 23046, 78, 0, 16915, 2, 13, 85275, 7451]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_features(tokenized_reviews, seq_length):\n",
        "\n",
        "\n",
        "    features = np.zeros((len(tokenized_reviews), seq_length), dtype=int)\n",
        "\n",
        "    for i, row in enumerate(tokenized_reviews):\n",
        "        features[i, -len(row):] = np.array(row)[:seq_length]\n",
        "\n",
        "    return features"
      ],
      "metadata": {
        "id": "kA2_rBH1klTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 200\n",
        "\n",
        "features = pad_features(tokenized_reviews, seq_length=seq_length)\n",
        "\n",
        "assert len(features)==len(tokenized_reviews), \"Features should have as many rows as reviews.\"\n",
        "assert len(features[0])==seq_length, \"Each feature row should contain seq_length values.\"\n",
        "\n",
        "print(features[:10,:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT4UMbEVkpLG",
        "outputId": "957fdd14-82a0-4d3d-89b6-e6bc8895316c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [ 16483     26      0     12 106210      0   1698     22     37     24\n",
            "     432      1     72     30    275      0    303      0    162    126]\n",
            " [  1935   1326     12      0   1403     60   3921   2019      3   4809\n",
            "      36      6   3172   7184    129   7951      0   2180   6098 166268]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [     0      0      0      0      0      0      0      0      0      0\n",
            "       0      0      0      0      0      0      0      0      0      0]\n",
            " [    56   4365      8    270    119    756    247    159    381      0\n",
            "       9   2669      0    148  21621     13      8     40      0    124]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split_frac = 0.8\n",
        "\n",
        "\n",
        "split_idx = int(len(features)*split_frac)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:]\n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:]\n",
        "\n",
        "test_idx = int(len(remaining_x)*0.5)\n",
        "val_x, test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y, test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape),\n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxiMbEF7kqGT",
        "outputId": "4e61aa27-5f79-49a5-ec5c-fb0119278e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(20000, 200) \n",
            "Validation set: \t(2500, 200) \n",
            "Test set: \t\t(2500, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "valid_data = TensorDataset(torch.from_numpy(val_x), torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "3sVjiupWktwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWqKzpzekwMl",
        "outputId": "63dae792-a635-4cf8-aa7d-46a30d1cae81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SentimentCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    The embedding layer + CNN model that will be used to perform sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embed_model, vocab_size, output_size, embedding_dim,\n",
        "                 num_filters=100, kernel_sizes=[3, 4, 5], freeze_embeddings=True, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super(SentimentCNN, self).__init__()\n",
        "\n",
        "        self.num_filters = num_filters\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        self.embedding.weight = nn.Parameter(torch.from_numpy(embed_model.vectors)) # all vectors\n",
        "\n",
        "        if freeze_embeddings:\n",
        "            self.embedding.requires_grad = False\n",
        "\n",
        "        self.convs_1d = nn.ModuleList([\n",
        "            nn.Conv2d(1, num_filters, (k, embedding_dim), padding=(k-2,0))\n",
        "            for k in kernel_sizes])\n",
        "\n",
        "        self.fc = nn.Linear(len(kernel_sizes) * num_filters, output_size)\n",
        "\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def conv_and_pool(self, x, conv):\n",
        "\n",
        "        x = F.relu(conv(x)).squeeze(3)\n",
        "\n",
        "\n",
        "        x_max = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "        return x_max\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Defines how a batch of inputs, x, passes through the model layers.\n",
        "        Returns a single, sigmoid-activated class score as output.\n",
        "        \"\"\"\n",
        "        embeds = self.embedding(x) # (batch_size, seq_length, embedding_dim)\n",
        "        embeds = embeds.unsqueeze(1)\n",
        "\n",
        "        conv_results = [self.conv_and_pool(embeds, conv) for conv in self.convs_1d]\n",
        "\n",
        "        x = torch.cat(conv_results, 1)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        logit = self.fc(x)\n",
        "\n",
        "        return self.sig(logit)\n"
      ],
      "metadata": {
        "id": "ZeNpmsv1k0nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(pretrained_words)\n",
        "output_size = 1 # binary class (1 or 0)\n",
        "embedding_dim = len(embed_lookup[pretrained_words[0]]) # 300-dim vectors\n",
        "num_filters = 50\n",
        "kernel_sizes = [3, 4, 5]\n",
        "\n",
        "net = SentimentCNN(embed_lookup, vocab_size, output_size, embedding_dim,\n",
        "                   num_filters, kernel_sizes)\n",
        "\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWJl-D_tk28u",
        "outputId": "fba6468a-4b92-4f6e-aa71-1a57817e02b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentCNN(\n",
            "  (embedding): Embedding(299567, 300)\n",
            "  (convs_1d): ModuleList(\n",
            "    (0): Conv2d(1, 50, kernel_size=(3, 300), stride=(1, 1), padding=(1, 0))\n",
            "    (1): Conv2d(1, 50, kernel_size=(4, 300), stride=(1, 1), padding=(2, 0))\n",
            "    (2): Conv2d(1, 50, kernel_size=(5, 300), stride=(1, 1), padding=(3, 0))\n",
            "  )\n",
            "  (fc): Linear(in_features=150, out_features=1, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr=0.0001\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "id": "xt8FP4uIk5CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, train_loader, epochs, print_every=100):\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        net.cuda()\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    net.train()\n",
        "    for e in range(epochs):\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            counter += 1\n",
        "\n",
        "            if(train_on_gpu):\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "            net.zero_grad()\n",
        "\n",
        "            output = net(inputs)\n",
        "\n",
        "            loss = criterion(output.squeeze(), labels.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if counter % print_every == 0:\n",
        "                val_losses = []\n",
        "                net.eval()\n",
        "                for inputs, labels in valid_loader:\n",
        "\n",
        "                    if(train_on_gpu):\n",
        "                        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                    output = net(inputs)\n",
        "                    val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                    val_losses.append(val_loss.item())\n",
        "\n",
        "                net.train()\n",
        "                print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                      \"Step: {}...\".format(counter),\n",
        "                      \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                      \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "metadata": {
        "id": "cOdwHXxak6s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training params\n",
        "\n",
        "epochs = 5\n",
        "print_every = 100\n",
        "\n",
        "train(net, train_loader, epochs, print_every=print_every)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzCXDhe5k8yV",
        "outputId": "43597ae2-2760-4afc-d3ee-ba2b671656d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5... Step: 100... Loss: 0.406385... Val Loss: 0.384643\n",
            "Epoch: 1/5... Step: 200... Loss: 0.350309... Val Loss: 0.376442\n",
            "Epoch: 2/5... Step: 300... Loss: 0.301196... Val Loss: 0.370810\n",
            "Epoch: 2/5... Step: 400... Loss: 0.219262... Val Loss: 0.365505\n",
            "Epoch: 3/5... Step: 500... Loss: 0.254454... Val Loss: 0.362414\n",
            "Epoch: 3/5... Step: 600... Loss: 0.293313... Val Loss: 0.357445\n",
            "Epoch: 4/5... Step: 700... Loss: 0.314134... Val Loss: 0.353194\n",
            "Epoch: 4/5... Step: 800... Loss: 0.262648... Val Loss: 0.350808\n",
            "Epoch: 5/5... Step: 900... Loss: 0.212762... Val Loss: 0.349754\n",
            "Epoch: 5/5... Step: 1000... Loss: 0.190611... Val Loss: 0.347954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "\n",
        "net.eval()\n",
        "for inputs, labels in test_loader:\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "    output = net(inputs)\n",
        "\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFhTSqqnk-bS",
        "outputId": "977e47ba-57a5-42db-dbd0-d92a0734f001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.365\n",
            "Test accuracy: 0.843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(embed_lookup, test_review):\n",
        "    test_review = test_review.lower() # lowercase\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    test_words = test_text.split()\n",
        "\n",
        "    tokenized_review = []\n",
        "    for word in test_words:\n",
        "        try:\n",
        "            idx = embed_lookup.vocab[word].index\n",
        "        except:\n",
        "            idx = 0\n",
        "        tokenized_review.append(idx)\n",
        "\n",
        "    return tokenized_review\n"
      ],
      "metadata": {
        "id": "Zb-yVvsAlCSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "def tokenize_review(embed_lookup, test_review):\n",
        "    test_review = test_review.lower() # lowercase\n",
        "    test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "    test_words = test_text.split()\n",
        "    print(test_words)\n",
        "    tokenized_review = []\n",
        "    for word in test_words:\n",
        "        try:\n",
        "            idx = embed_lookup.key_to_index[word]\n",
        "        except:\n",
        "            idx = 0\n",
        "        tokenized_review.append(idx)\n",
        "\n",
        "    return tokenized_review\n"
      ],
      "metadata": {
        "id": "Mwoc6l2UlGRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(embed_lookup, net, test_review, sequence_length=200):\n",
        "    \"\"\"\n",
        "    Predict whether a given test_review has negative or positive sentiment.\n",
        "    \"\"\"\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    test_ints = tokenize_review(embed_lookup, test_review)\n",
        "    print(test_ints)\n",
        "    seq_length=sequence_length\n",
        "    features = pad_features([test_ints], seq_length)\n",
        "\n",
        "    feature_tensor = torch.from_numpy(features)\n",
        "\n",
        "    batch_size = feature_tensor.size(0)\n",
        "\n",
        "    if(train_on_gpu):\n",
        "        feature_tensor = feature_tensor.cuda()\n",
        "\n",
        "    output = net(feature_tensor)\n",
        "\n",
        "    pred = torch.round(output.squeeze())\n",
        "    print('Prediction value, pre-rounding: {:.6f}'.format(output.item()))\n",
        "\n",
        "    if(pred.item()==1):\n",
        "        print(\"Positive review detected!\")\n",
        "    else:\n",
        "        print(\"Negative review detected.\")\n"
      ],
      "metadata": {
        "id": "TPDbplwnlVad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length=200\n"
      ],
      "metadata": {
        "id": "ragc9FyIlbxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# negative test review\n",
        "test_review_pos = 'Best Movie i have ever seen.'\n",
        "\n",
        "# test negative review\n",
        "predict(embed_lookup, net, test_review_pos, seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hhn6p6buldCH",
        "outputId": "52efac83-b97b-42a1-ee7c-e99e747d6835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['best', 'movie', 'i', 'have', 'ever', 'seen']\n",
            "[189, 1083, 4365, 19, 491, 441]\n",
            "Prediction value, pre-rounding: 0.945987\n",
            "Positive review detected!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# negative test review\n",
        "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting and the dialogue was slow.'\n",
        "\n",
        "# test negative review\n",
        "predict(embed_lookup, net, test_review_neg, seq_length)"
      ],
      "metadata": {
        "id": "xf925UiFli5J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa746f8-d445-4724-b0a1-3eb3e531edf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'worst', 'movie', 'i', 'have', 'seen', 'acting', 'was', 'terrible', 'and', 'i', 'want', 'my', 'money', 'back', 'this', 'movie', 'had', 'bad', 'acting', 'and', 'the', 'dialogue', 'was', 'slow']\n",
            "[9, 1398, 1083, 4365, 19, 441, 2456, 8, 4758, 0, 4365, 177, 119, 222, 90, 25, 1083, 31, 675, 2456, 0, 9, 3910, 8, 1750]\n",
            "Prediction value, pre-rounding: 0.004265\n",
            "Negative review detected.\n"
          ]
        }
      ]
    }
  ]
}