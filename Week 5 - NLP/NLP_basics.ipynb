{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e11f8a0",
      "metadata": {
        "id": "3e11f8a0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb11d12",
      "metadata": {
        "id": "fcb11d12"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/Users/abdullahmunir/Desktop/ATOMCAMP/NLP/NLP_Assignment_1/sentiment_tweets3.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b77d0c4b",
      "metadata": {
        "id": "b77d0c4b",
        "outputId": "56b63dd8-5509-4564-cec4-e8b2100e67d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Index</th>\n",
              "      <th>message to examine</th>\n",
              "      <th>label (depression result)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>106</td>\n",
              "      <td>just had a real good moment. i missssssssss hi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>217</td>\n",
              "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>220</td>\n",
              "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>288</td>\n",
              "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>540</td>\n",
              "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>624</td>\n",
              "      <td>so sleepy. good times tonight though</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>701</td>\n",
              "      <td>@SilkCharm re: #nbn as someone already said, d...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>808</td>\n",
              "      <td>23 or 24ï¿½C possible today. Nice</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1193</td>\n",
              "      <td>nite twitterville  workout in the am  -ciao</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1324</td>\n",
              "      <td>@daNanner Night, darlin'!  Sweet dreams to you</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1332</td>\n",
              "      <td>Good morning everybody!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1368</td>\n",
              "      <td>Finally! I just created my WordPress Blog. The...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1578</td>\n",
              "      <td>kisha they cnt get over u til they get out frm...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1595</td>\n",
              "      <td>@nicolerichie Yes i remember that band, It was...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1861</td>\n",
              "      <td>I really love reflections and shadows</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1889</td>\n",
              "      <td>@blueaero ooo it's fantasy?  i like fantasy no...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1899</td>\n",
              "      <td>@rokchic28 no probs, I sell nothing other than...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1919</td>\n",
              "      <td>@shipovalov &amp;quot;NOKLA connecting people&amp;quot...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>1992</td>\n",
              "      <td>Once again stayed up to late and have to start...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2097</td>\n",
              "      <td>@Kal_Penn I just read about your new job, CONG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2126</td>\n",
              "      <td>haven't been able to sleep at ALL. i think i'l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2218</td>\n",
              "      <td>woo thanks ron and steeve for following me yeo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2271</td>\n",
              "      <td>@aidenchan yeah sure but its my sister's so ta...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2468</td>\n",
              "      <td>@sian_the_mouse yay! a duck! if i want anythin...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2656</td>\n",
              "      <td>smaaack that ass! hahhahahaa  i make myself la...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2723</td>\n",
              "      <td>woo. its late! haha  goodnight twitterverse! xoxo</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2763</td>\n",
              "      <td>Looking forward to the meeting with Pastor Kon...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2792</td>\n",
              "      <td>@doubleickey u know those minichocolates in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2853</td>\n",
              "      <td>Testing to see if twitter works thro facebook</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2874</td>\n",
              "      <td>NIGHT babies. Got a VH1 thing in the am  Check...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Index                                 message to examine  \\\n",
              "0     106  just had a real good moment. i missssssssss hi...   \n",
              "1     217         is reading manga  http://plurk.com/p/mzp1e   \n",
              "2     220  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
              "3     288  @lapcat Need to send 'em to my accountant tomo...   \n",
              "4     540      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
              "5     624              so sleepy. good times tonight though    \n",
              "6     701  @SilkCharm re: #nbn as someone already said, d...   \n",
              "7     808                 23 or 24ï¿½C possible today. Nice    \n",
              "8    1193        nite twitterville  workout in the am  -ciao   \n",
              "9    1324    @daNanner Night, darlin'!  Sweet dreams to you    \n",
              "10   1332                           Good morning everybody!    \n",
              "11   1368  Finally! I just created my WordPress Blog. The...   \n",
              "12   1578  kisha they cnt get over u til they get out frm...   \n",
              "13   1595  @nicolerichie Yes i remember that band, It was...   \n",
              "14   1861             I really love reflections and shadows    \n",
              "15   1889  @blueaero ooo it's fantasy?  i like fantasy no...   \n",
              "16   1899  @rokchic28 no probs, I sell nothing other than...   \n",
              "17   1919  @shipovalov &quot;NOKLA connecting people&quot...   \n",
              "18   1992  Once again stayed up to late and have to start...   \n",
              "19   2097  @Kal_Penn I just read about your new job, CONG...   \n",
              "20   2126  haven't been able to sleep at ALL. i think i'l...   \n",
              "21   2218  woo thanks ron and steeve for following me yeo...   \n",
              "22   2271  @aidenchan yeah sure but its my sister's so ta...   \n",
              "23   2468  @sian_the_mouse yay! a duck! if i want anythin...   \n",
              "24   2656  smaaack that ass! hahhahahaa  i make myself la...   \n",
              "25   2723  woo. its late! haha  goodnight twitterverse! xoxo   \n",
              "26   2763  Looking forward to the meeting with Pastor Kon...   \n",
              "27   2792  @doubleickey u know those minichocolates in th...   \n",
              "28   2853     Testing to see if twitter works thro facebook    \n",
              "29   2874  NIGHT babies. Got a VH1 thing in the am  Check...   \n",
              "\n",
              "    label (depression result)  \n",
              "0                           0  \n",
              "1                           0  \n",
              "2                           0  \n",
              "3                           0  \n",
              "4                           0  \n",
              "5                           0  \n",
              "6                           0  \n",
              "7                           0  \n",
              "8                           0  \n",
              "9                           0  \n",
              "10                          0  \n",
              "11                          0  \n",
              "12                          0  \n",
              "13                          0  \n",
              "14                          0  \n",
              "15                          0  \n",
              "16                          0  \n",
              "17                          0  \n",
              "18                          0  \n",
              "19                          0  \n",
              "20                          0  \n",
              "21                          0  \n",
              "22                          0  \n",
              "23                          0  \n",
              "24                          0  \n",
              "25                          0  \n",
              "26                          0  \n",
              "27                          0  \n",
              "28                          0  \n",
              "29                          0  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79b6d345",
      "metadata": {
        "id": "79b6d345",
        "outputId": "6ac20dc3-8240-4322-b3a6-973b18659588"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10314 entries, 0 to 10313\n",
            "Data columns (total 3 columns):\n",
            " #   Column                     Non-Null Count  Dtype \n",
            "---  ------                     --------------  ----- \n",
            " 0   Index                      10314 non-null  int64 \n",
            " 1   message to examine         10314 non-null  object\n",
            " 2   label (depression result)  10314 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 241.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b872e29",
      "metadata": {
        "id": "9b872e29"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5094c8b",
      "metadata": {
        "id": "b5094c8b",
        "outputId": "bd1f8f8b-0097-4c55-ecc1-be22ade11f97"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>message to examine</th>\n",
              "      <th>cleaned_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>just had a real good moment. i missssssssss hi...</td>\n",
              "      <td>just had a real good moment i missssssssss him...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is reading manga  http://plurk.com/p/mzp1e</td>\n",
              "      <td>is reading manga</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@comeagainjen http://twitpic.com/2y2lx - http:...</td>\n",
              "      <td>comeagainjen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@lapcat Need to send 'em to my accountant tomo...</td>\n",
              "      <td>lapcat need to send em to my accountant tomorr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ADD ME ON MYSPACE!!!  myspace.com/LookThunder</td>\n",
              "      <td>add me on myspace  myspacecomlookthunder</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  message to examine  \\\n",
              "0  just had a real good moment. i missssssssss hi...   \n",
              "1         is reading manga  http://plurk.com/p/mzp1e   \n",
              "2  @comeagainjen http://twitpic.com/2y2lx - http:...   \n",
              "3  @lapcat Need to send 'em to my accountant tomo...   \n",
              "4      ADD ME ON MYSPACE!!!  myspace.com/LookThunder   \n",
              "\n",
              "                                        cleaned_text  \n",
              "0  just had a real good moment i missssssssss him...  \n",
              "1                                 is reading manga    \n",
              "2                                   comeagainjen      \n",
              "3  lapcat need to send em to my accountant tomorr...  \n",
              "4           add me on myspace  myspacecomlookthunder  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Text Cleaning Time\n",
        "import re\n",
        "\n",
        "import string\n",
        "\n",
        "# Function to clean text by removing URLs, punctuation, and converting to lowercase\n",
        "def clean_text(text):\n",
        "    # Removing URLs\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "\n",
        "    # Removing punctuation\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Converting text to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to 'message to examine'\n",
        "df['cleaned_text'] = df['message to examine'].apply(clean_text)\n",
        "\n",
        "# Display the first few rows to check the cleaned text\n",
        "df[['message to examine', 'cleaned_text']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "497ffdf3",
      "metadata": {
        "id": "497ffdf3",
        "outputId": "fca56aad-e65d-4b95-9ca4-339437b143d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /Users/abdullahmunir/anaconda3/lib/python3.11/site-packages (3.8.1)\r\n",
            "Requirement already satisfied: click in /Users/abdullahmunir/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\r\n",
            "Requirement already satisfied: joblib in /Users/abdullahmunir/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\r\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/abdullahmunir/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\r\n",
            "Requirement already satisfied: tqdm in /Users/abdullahmunir/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\r\n"
          ]
        }
      ],
      "source": [
        "# Tokenization time\n",
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39b9b26c",
      "metadata": {
        "id": "39b9b26c",
        "outputId": "9f90c5c7-a8f5-403a-a398-811b31a45f4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/abdullahmunir/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>just had a real good moment i missssssssss him...</td>\n",
              "      <td>[just, had, a, real, good, moment, i, missssss...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is reading manga</td>\n",
              "      <td>[is, reading, manga]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>comeagainjen</td>\n",
              "      <td>[comeagainjen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lapcat need to send em to my accountant tomorr...</td>\n",
              "      <td>[lapcat, need, to, send, em, to, my, accountan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>add me on myspace  myspacecomlookthunder</td>\n",
              "      <td>[add, me, on, myspace, myspacecomlookthunder]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        cleaned_text  \\\n",
              "0  just had a real good moment i missssssssss him...   \n",
              "1                                 is reading manga     \n",
              "2                                   comeagainjen       \n",
              "3  lapcat need to send em to my accountant tomorr...   \n",
              "4           add me on myspace  myspacecomlookthunder   \n",
              "\n",
              "                                              tokens  \n",
              "0  [just, had, a, real, good, moment, i, missssss...  \n",
              "1                               [is, reading, manga]  \n",
              "2                                     [comeagainjen]  \n",
              "3  [lapcat, need, to, send, em, to, my, accountan...  \n",
              "4      [add, me, on, myspace, myspacecomlookthunder]  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Downloading the tokenizer model\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to tokenize text\n",
        "def tokenize_text(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "# Apply tokenization to the cleaned text\n",
        "df['tokens'] = df['cleaned_text'].apply(tokenize_text)\n",
        "\n",
        "# Display the first few rows to check the tokenization results\n",
        "df[['cleaned_text', 'tokens']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bfb04a3",
      "metadata": {
        "id": "4bfb04a3",
        "outputId": "83364042-b054-4308-b869-332234071c92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/abdullahmunir/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Removing Stop words\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Downloading the list of stop words\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Set of English stop words\n",
        "stop_words = set(stopwords.words('english'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cefbfa9",
      "metadata": {
        "id": "3cefbfa9",
        "outputId": "933e0a67-1eab-4475-c33d-4f8d071625d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>filtered_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[just, had, a, real, good, moment, i, missssss...</td>\n",
              "      <td>[real, good, moment, missssssssss, much]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[is, reading, manga]</td>\n",
              "      <td>[reading, manga]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[comeagainjen]</td>\n",
              "      <td>[comeagainjen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[lapcat, need, to, send, em, to, my, accountan...</td>\n",
              "      <td>[lapcat, need, send, em, accountant, tomorrow,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[add, me, on, myspace, myspacecomlookthunder]</td>\n",
              "      <td>[add, myspace, myspacecomlookthunder]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tokens  \\\n",
              "0  [just, had, a, real, good, moment, i, missssss...   \n",
              "1                               [is, reading, manga]   \n",
              "2                                     [comeagainjen]   \n",
              "3  [lapcat, need, to, send, em, to, my, accountan...   \n",
              "4      [add, me, on, myspace, myspacecomlookthunder]   \n",
              "\n",
              "                                     filtered_tokens  \n",
              "0           [real, good, moment, missssssssss, much]  \n",
              "1                                   [reading, manga]  \n",
              "2                                     [comeagainjen]  \n",
              "3  [lapcat, need, send, em, accountant, tomorrow,...  \n",
              "4              [add, myspace, myspacecomlookthunder]  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Function to remove stop words\n",
        "def remove_stop_words(tokens):\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    return filtered_tokens\n",
        "\n",
        "# Apply the function to remove stop words from the tokens\n",
        "df['filtered_tokens'] = df['tokens'].apply(remove_stop_words)\n",
        "\n",
        "# Display the first few rows to check the results\n",
        "df[['tokens', 'filtered_tokens']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "197f9db8",
      "metadata": {
        "id": "197f9db8",
        "outputId": "7a6428f9-4741-4c8e-b752-1d907d79cb64"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filtered_tokens</th>\n",
              "      <th>stemmed_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[real, good, moment, missssssssss, much]</td>\n",
              "      <td>[real, good, moment, missssssssss, much]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[reading, manga]</td>\n",
              "      <td>[read, manga]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[comeagainjen]</td>\n",
              "      <td>[comeagainjen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[lapcat, need, send, em, accountant, tomorrow,...</td>\n",
              "      <td>[lapcat, need, send, em, account, tomorrow, od...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[add, myspace, myspacecomlookthunder]</td>\n",
              "      <td>[add, myspac, myspacecomlookthund]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     filtered_tokens  \\\n",
              "0           [real, good, moment, missssssssss, much]   \n",
              "1                                   [reading, manga]   \n",
              "2                                     [comeagainjen]   \n",
              "3  [lapcat, need, send, em, accountant, tomorrow,...   \n",
              "4              [add, myspace, myspacecomlookthunder]   \n",
              "\n",
              "                                      stemmed_tokens  \n",
              "0           [real, good, moment, missssssssss, much]  \n",
              "1                                      [read, manga]  \n",
              "2                                     [comeagainjen]  \n",
              "3  [lapcat, need, send, em, account, tomorrow, od...  \n",
              "4                 [add, myspac, myspacecomlookthund]  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Implementing stemming\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Initialize the Porter Stemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Function to stem tokens\n",
        "def stem_tokens(tokens):\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    return stemmed_tokens\n",
        "\n",
        "# Apply stemming to the filtered tokens\n",
        "df['stemmed_tokens'] = df['filtered_tokens'].apply(stem_tokens)\n",
        "\n",
        "# Display the first few rows to check the stemmed results\n",
        "df[['filtered_tokens', 'stemmed_tokens']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5149454",
      "metadata": {
        "id": "d5149454",
        "outputId": "2f10dc62-9da4-40bd-8ae2-9fff13719463"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/abdullahmunir/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filtered_tokens</th>\n",
              "      <th>lemmatized_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[real, good, moment, missssssssss, much]</td>\n",
              "      <td>[real, good, moment, miss, much]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[reading, manga]</td>\n",
              "      <td>[reading, manga]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[comeagainjen]</td>\n",
              "      <td>[comeagainjen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[lapcat, need, send, em, accountant, tomorrow,...</td>\n",
              "      <td>[lapcat, need, send, em, accountant, tomorrow,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[add, myspace, myspacecomlookthunder]</td>\n",
              "      <td>[add, myspace, myspacecomlookthunder]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     filtered_tokens  \\\n",
              "0           [real, good, moment, missssssssss, much]   \n",
              "1                                   [reading, manga]   \n",
              "2                                     [comeagainjen]   \n",
              "3  [lapcat, need, send, em, accountant, tomorrow,...   \n",
              "4              [add, myspace, myspacecomlookthunder]   \n",
              "\n",
              "                                   lemmatized_tokens  \n",
              "0                   [real, good, moment, miss, much]  \n",
              "1                                   [reading, manga]  \n",
              "2                                     [comeagainjen]  \n",
              "3  [lapcat, need, send, em, accountant, tomorrow,...  \n",
              "4              [add, myspace, myspacecomlookthunder]  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Implementing lemmatization\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Downloading the WordNet resource\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize the WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Function to lemmatize tokens\n",
        "def lemmatize_tokens(tokens):\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return lemmatized_tokens\n",
        "\n",
        "# Apply lemmatization to the filtered tokens\n",
        "df['lemmatized_tokens'] = df['filtered_tokens'].apply(lemmatize_tokens)\n",
        "\n",
        "# Display the first few rows to check the lemmatized results\n",
        "df[['filtered_tokens', 'lemmatized_tokens']].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc8448b6",
      "metadata": {
        "id": "fc8448b6",
        "outputId": "7ba8d10e-44d4-45e6-fe51-b1f6c2f1f7fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filtered_tokens</th>\n",
              "      <th>stemmed_tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[real, good, moment, missssssssss, much]</td>\n",
              "      <td>[real, good, moment, missssssssss, much]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[reading, manga]</td>\n",
              "      <td>[read, manga]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[comeagainjen]</td>\n",
              "      <td>[comeagainjen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[lapcat, need, send, em, accountant, tomorrow,...</td>\n",
              "      <td>[lapcat, need, send, em, account, tomorrow, od...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[add, myspace, myspacecomlookthunder]</td>\n",
              "      <td>[add, myspac, myspacecomlookthund]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[sleepy, good, times, tonight, though]</td>\n",
              "      <td>[sleepi, good, time, tonight, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[silkcharm, nbn, someone, already, said, fiber...</td>\n",
              "      <td>[silkcharm, nbn, someon, alreadi, said, fiber,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[23, 24ï¿½c, possible, today, nice]</td>\n",
              "      <td>[23, 24ï¿½c, possibl, today, nice]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[nite, twitterville, workout, ciao]</td>\n",
              "      <td>[nite, twittervil, workout, ciao]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[dananner, night, darlin, sweet, dreams]</td>\n",
              "      <td>[danann, night, darlin, sweet, dream]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>[good, morning, everybody]</td>\n",
              "      <td>[good, morn, everybodi]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>[finally, created, wordpress, blog, theres, al...</td>\n",
              "      <td>[final, creat, wordpress, blog, there, alreadi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>[kisha, cnt, get, u, til, get, frm, u, remembe...</td>\n",
              "      <td>[kisha, cnt, get, u, til, get, frm, u, rememb,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>[nicolerichie, yes, remember, band, awesome, p...</td>\n",
              "      <td>[nicolerichi, ye, rememb, band, awesom, pleas,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>[really, love, reflections, shadows]</td>\n",
              "      <td>[realli, love, reflect, shadow]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>[blueaero, ooo, fantasy, like, fantasy, novels...</td>\n",
              "      <td>[blueaero, ooo, fantasi, like, fantasi, novel,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>[rokchic28, probs, sell, nothing, blog, ill, g...</td>\n",
              "      <td>[rokchic28, prob, sell, noth, blog, ill, get, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>[shipovalov, quotnokla, connecting, peoplequot]</td>\n",
              "      <td>[shipovalov, quotnokla, connect, peoplequot]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>[stayed, late, start, early, good, thing, like...</td>\n",
              "      <td>[stay, late, start, earli, good, thing, like, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>[kalpenn, read, new, job, congratulations, tha...</td>\n",
              "      <td>[kalpenn, read, new, job, congratul, that, fan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>[havent, able, sleep, think, ill, watch, ugly,...</td>\n",
              "      <td>[havent, abl, sleep, think, ill, watch, ugli, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>[woo, thanks, ron, steeve, following, yeow, fo...</td>\n",
              "      <td>[woo, thank, ron, steev, follow, yeow, folower...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>[aidenchan, yeah, sure, sisters, take, extra, ...</td>\n",
              "      <td>[aidenchan, yeah, sure, sister, take, extra, g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>[sianthemouse, yay, duck, want, anything, watc...</td>\n",
              "      <td>[sianthemous, yay, duck, want, anyth, watch, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>[smaaack, ass, hahhahahaa, make, laugh, oooooh...</td>\n",
              "      <td>[smaaack, ass, hahhahahaa, make, laugh, oooooh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>[woo, late, haha, goodnight, twitterverse, xoxo]</td>\n",
              "      <td>[woo, late, haha, goodnight, twittervers, xoxo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>[looking, forward, meeting, pastor, kong, jw, ...</td>\n",
              "      <td>[look, forward, meet, pastor, kong, jw, later]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>[doubleickey, u, know, minichocolates, shape, ...</td>\n",
              "      <td>[doubleickey, u, know, minichocol, shape, liqu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>[testing, see, twitter, works, thro, facebook]</td>\n",
              "      <td>[test, see, twitter, work, thro, facebook]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>[night, babies, got, vh1, thing, check, pics]</td>\n",
              "      <td>[night, babi, got, vh1, thing, check, pic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      filtered_tokens  \\\n",
              "0            [real, good, moment, missssssssss, much]   \n",
              "1                                    [reading, manga]   \n",
              "2                                      [comeagainjen]   \n",
              "3   [lapcat, need, send, em, accountant, tomorrow,...   \n",
              "4               [add, myspace, myspacecomlookthunder]   \n",
              "5              [sleepy, good, times, tonight, though]   \n",
              "6   [silkcharm, nbn, someone, already, said, fiber...   \n",
              "7                 [23, 24ï¿½c, possible, today, nice]   \n",
              "8                 [nite, twitterville, workout, ciao]   \n",
              "9            [dananner, night, darlin, sweet, dreams]   \n",
              "10                         [good, morning, everybody]   \n",
              "11  [finally, created, wordpress, blog, theres, al...   \n",
              "12  [kisha, cnt, get, u, til, get, frm, u, remembe...   \n",
              "13  [nicolerichie, yes, remember, band, awesome, p...   \n",
              "14               [really, love, reflections, shadows]   \n",
              "15  [blueaero, ooo, fantasy, like, fantasy, novels...   \n",
              "16  [rokchic28, probs, sell, nothing, blog, ill, g...   \n",
              "17    [shipovalov, quotnokla, connecting, peoplequot]   \n",
              "18  [stayed, late, start, early, good, thing, like...   \n",
              "19  [kalpenn, read, new, job, congratulations, tha...   \n",
              "20  [havent, able, sleep, think, ill, watch, ugly,...   \n",
              "21  [woo, thanks, ron, steeve, following, yeow, fo...   \n",
              "22  [aidenchan, yeah, sure, sisters, take, extra, ...   \n",
              "23  [sianthemouse, yay, duck, want, anything, watc...   \n",
              "24  [smaaack, ass, hahhahahaa, make, laugh, oooooh...   \n",
              "25   [woo, late, haha, goodnight, twitterverse, xoxo]   \n",
              "26  [looking, forward, meeting, pastor, kong, jw, ...   \n",
              "27  [doubleickey, u, know, minichocolates, shape, ...   \n",
              "28     [testing, see, twitter, works, thro, facebook]   \n",
              "29      [night, babies, got, vh1, thing, check, pics]   \n",
              "\n",
              "                                       stemmed_tokens  \n",
              "0            [real, good, moment, missssssssss, much]  \n",
              "1                                       [read, manga]  \n",
              "2                                      [comeagainjen]  \n",
              "3   [lapcat, need, send, em, account, tomorrow, od...  \n",
              "4                  [add, myspac, myspacecomlookthund]  \n",
              "5               [sleepi, good, time, tonight, though]  \n",
              "6   [silkcharm, nbn, someon, alreadi, said, fiber,...  \n",
              "7                  [23, 24ï¿½c, possibl, today, nice]  \n",
              "8                   [nite, twittervil, workout, ciao]  \n",
              "9               [danann, night, darlin, sweet, dream]  \n",
              "10                            [good, morn, everybodi]  \n",
              "11  [final, creat, wordpress, blog, there, alreadi...  \n",
              "12  [kisha, cnt, get, u, til, get, frm, u, rememb,...  \n",
              "13  [nicolerichi, ye, rememb, band, awesom, pleas,...  \n",
              "14                    [realli, love, reflect, shadow]  \n",
              "15  [blueaero, ooo, fantasi, like, fantasi, novel,...  \n",
              "16  [rokchic28, prob, sell, noth, blog, ill, get, ...  \n",
              "17       [shipovalov, quotnokla, connect, peoplequot]  \n",
              "18  [stay, late, start, earli, good, thing, like, ...  \n",
              "19  [kalpenn, read, new, job, congratul, that, fan...  \n",
              "20  [havent, abl, sleep, think, ill, watch, ugli, ...  \n",
              "21  [woo, thank, ron, steev, follow, yeow, folower...  \n",
              "22  [aidenchan, yeah, sure, sister, take, extra, g...  \n",
              "23  [sianthemous, yay, duck, want, anyth, watch, i...  \n",
              "24  [smaaack, ass, hahhahahaa, make, laugh, oooooh...  \n",
              "25    [woo, late, haha, goodnight, twittervers, xoxo]  \n",
              "26     [look, forward, meet, pastor, kong, jw, later]  \n",
              "27  [doubleickey, u, know, minichocol, shape, liqu...  \n",
              "28         [test, see, twitter, work, thro, facebook]  \n",
              "29         [night, babi, got, vh1, thing, check, pic]  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df[['filtered_tokens', 'stemmed_tokens']].head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18625e4b",
      "metadata": {
        "id": "18625e4b",
        "outputId": "7d8d5645-5a53-4b7d-f89b-7b3ef15d3981"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>just had a real good moment i missssssssss him...</td>\n",
              "      <td>[just had a real good moment i missssssssss hi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is reading manga</td>\n",
              "      <td>[is reading manga]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>comeagainjen</td>\n",
              "      <td>[comeagainjen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lapcat need to send em to my accountant tomorr...</td>\n",
              "      <td>[lapcat need to send em to my accountant tomor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>add me on myspace  myspacecomlookthunder</td>\n",
              "      <td>[add me on myspace  myspacecomlookthunder]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        cleaned_text  \\\n",
              "0  just had a real good moment i missssssssss him...   \n",
              "1                                 is reading manga     \n",
              "2                                   comeagainjen       \n",
              "3  lapcat need to send em to my accountant tomorr...   \n",
              "4           add me on myspace  myspacecomlookthunder   \n",
              "\n",
              "                                           sentences  \n",
              "0  [just had a real good moment i missssssssss hi...  \n",
              "1                                 [is reading manga]  \n",
              "2                                     [comeagainjen]  \n",
              "3  [lapcat need to send em to my accountant tomor...  \n",
              "4         [add me on myspace  myspacecomlookthunder]  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sentence Segmentation\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Function to segment text into sentences\n",
        "def segment_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    return sentences\n",
        "\n",
        "# Apply sentence segmentation to the cleaned text\n",
        "df['sentences'] = df['cleaned_text'].apply(segment_sentences)\n",
        "\n",
        "# Display the first few rows to check the sentence segmentation results\n",
        "df[['cleaned_text', 'sentences']].head()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}